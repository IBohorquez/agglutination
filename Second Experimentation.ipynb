{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Second Experimentation.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1D1AbVPJXnftdvUuAnPs46l9kEefVx6AG","authorship_tag":"ABX9TyNXsbZ53GElUCy8zJWohzNP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCG2IKvcs895","executionInfo":{"status":"ok","timestamp":1631682996438,"user_tz":300,"elapsed":386,"user":{"displayName":"MARIO ISAAC SALGUEDO BOHORQUEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvTo7MXgDxQwdUpjCHglQVpHuGZBo0Uu-K3u0G=s64","userId":"15580766531341648609"}},"outputId":"fa9947c4-09c4-4f91-ffaf-6e50188022a9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"Sj555VBQUHS5"},"source":["#Importing Libraries"]},{"cell_type":"code","metadata":{"id":"7RVxvnG3tAcv"},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential, Model, load_model\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","import pickle\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from skimage import io\n","from skimage.color import rgb2gray\n","from skimage.transform import resize\n","import random\n","from tqdm import tqdm\n","\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y7imhMdiUNX_"},"source":["#Reading pre-processed dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPJR0nI_tAfW","executionInfo":{"status":"ok","timestamp":1631683029657,"user_tz":300,"elapsed":24850,"user":{"displayName":"MARIO ISAAC SALGUEDO BOHORQUEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvTo7MXgDxQwdUpjCHglQVpHuGZBo0Uu-K3u0G=s64","userId":"15580766531341648609"}},"outputId":"70f2112e-9e7b-46dc-f300-4c9e1013143d"},"source":["####################################\n","## Reading the pre-processed dataset\n","\n","path_X = '/content/drive/MyDrive/Agglutination/Dataset/Pre-Processed Dataset/' + 'Xcrop_rgb_v2.pickle'\n","path_y = '/content/drive/MyDrive/Agglutination/Dataset/Pre-Processed Dataset/' + 'ycrop_rgb_v2.pickle'\n","\n","pickle_in = open(path_X, \"rb\")\n","X = pickle.load(pickle_in)\n","pickle_in.close()\n","\n","pickle_in = open(path_y, \"rb\")\n","y = pickle.load(pickle_in)\n","pickle_in.close()\n","\n","print(X.shape, y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1285, 224, 224, 3) (1285,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"RqQQ1Y5kS_2B"},"source":["#For saving the calculated metrics"]},{"cell_type":"code","metadata":{"id":"Q0ypkzvktAnG"},"source":["accuracies = []\n","precisions = []\n","sensitivities = []\n","specificities = []\n","F1_scores = []\n","auc_values = []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rnLJNn_gRjns"},"source":["#Training and Testing the model using 5-fold cross-validation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcgEZxYetAp2","executionInfo":{"status":"ok","timestamp":1631685915886,"user_tz":300,"elapsed":1346643,"user":{"displayName":"MARIO ISAAC SALGUEDO BOHORQUEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvTo7MXgDxQwdUpjCHglQVpHuGZBo0Uu-K3u0G=s64","userId":"15580766531341648609"}},"outputId":"9ac80ffa-50bd-4bff-f927-e68ce04d1679"},"source":["from sklearn.model_selection import StratifiedKFold\n","\n","n = 5\n","j = 0\n","folds = StratifiedKFold(n_splits=n)\n","\n","for train_index, test_index in folds.split(X, y):\n","\n","    print('--------------')\n","    print('ITERATION:', j+1)\n","    print('--------------')\n","\n","    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n","\n","    print()\n","    print('---------------------------------------------------------------------------')\n","    print('There are', X_train.shape[0], 'images for the Training with their respectives', y_train.shape[0], 'labels.')\n","    print('There are', X_test.shape[0], 'images for the Testing with their respectives', y_test.shape[0], 'labels.')\n","    print('---------------------------------------------------------------------------')\n","    print()\n","\n","    print()\n","    print('-----------------------------------------------------------------------------------------------------------')\n","    sum_neg = 0\n","    sum_pos = 0\n","\n","    for i in range(len(y_train)):\n","        if y_train[i]==0:\n","            sum_neg += 1\n","        else:\n","            sum_pos +=1 \n","\n","    print('There are', sum_neg, 'negatives images and', sum_pos, 'positives images on the Training dataset: rate=', sum_neg/sum_pos)\n","\n","    sum_neg = 0\n","    sum_pos = 0\n","\n","    for i in range(len(y_test)):\n","        if y_test[i]==0:\n","            sum_neg += 1\n","        else:\n","            sum_pos +=1 \n","\n","    print('There are', sum_neg, 'negatives images and', sum_pos, 'positives images on the Testing dataset: rate=', sum_neg/sum_pos)\n","    print('-----------------------------------------------------------------------------------------------------------')\n","    print()\n","\n","    ########################################\n","    ## Defining the Transfer Learning model\n","\n","    conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    conv_base.trainable = False\n","\n","    model = None\n","    model = Sequential()\n","    model.add(conv_base)\n","    model.add(Flatten())\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0005), metrics=['accuracy'])\n","\n","    print(model.summary())\n","    print()\n","    print('------------------------------------')\n","    print('Training the Tranfer Learning Model')\n","    print('------------------------------------')\n","    print()\n","\n","    ######################\n","    ## Training the model\n","\n","    history = model.fit(X_train, y_train, batch_size=32, epochs=30, shuffle=False, verbose=1)\n","\n","    print()\n","    print('------------------------')\n","    print('Evaluation of the Model')\n","    print('------------------------')\n","\n","    ############################################\n","    ## Testing the model on the Testing dataset\n","\n","    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","    print()\n","    print('Accuracy on the Testing dataset:', test_accuracy*100, '%')\n","    print()\n","\n","    #######################\n","    ## Calculating metrics\n","\n","    y_preds = model.predict(X_test).ravel()\n","    fpr, tpr, thresholds = roc_curve(y_test, y_preds)\n","    auc_value = auc(fpr, tpr)\n","\n","    mythreshold = 0.5\n","    y_pred = (model.predict(X_test)>= mythreshold).astype(int)\n","    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","\n","    acc = (tn + tp)/(tn + fp + fn + tp)\n","    prec = tp/(tp + fp)\n","    sens = tp/(tp + fn)\n","    spec = tn/(tn + fp)\n","    f1_score = (2*prec*sens)/(prec + sens)\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    sensitivities.append(sens)\n","    specificities.append(spec)\n","    F1_scores.append(f1_score)\n","    auc_values.append(auc_value)\n","\n","    ##############################\n","    ## Saving all the five models \n","\n","    model.save('/content/drive/MyDrive/Agglutination Google Project/cross-validaton models/' + 'cv_model_acc_{:4f}_iter_{}.h5'.format(test_accuracy,j+1))\n","    j += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------\n","ITERATION: 1\n","--------------\n","\n","---------------------------------------------------------------------------\n","There are 1028 images for the Training with their respectives 1028 labels.\n","There are 257 images for the Testing with their respectives 257 labels.\n","---------------------------------------------------------------------------\n","\n","\n","-----------------------------------------------------------------------------------------------------------\n","There are 496 negatives images and 532 positives images on the Training dataset: rate= 0.9323308270676691\n","There are 124 negatives images and 133 positives images on the Testing dataset: rate= 0.9323308270676691\n","-----------------------------------------------------------------------------------------------------------\n","\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 256)               6422784   \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 21,137,729\n","Trainable params: 6,423,041\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n","\n","------------------------------------\n","Training the Tranfer Learning Model\n","------------------------------------\n","\n","Epoch 1/30\n","33/33 [==============================] - 9s 246ms/step - loss: 0.6668 - accuracy: 0.7451\n","Epoch 2/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.1916 - accuracy: 0.9222\n","Epoch 3/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1749 - accuracy: 0.9270\n","Epoch 4/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1673 - accuracy: 0.9280\n","Epoch 5/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1606 - accuracy: 0.9309\n","Epoch 6/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1550 - accuracy: 0.9358\n","Epoch 7/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1499 - accuracy: 0.9368\n","Epoch 8/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.1451 - accuracy: 0.9387\n","Epoch 9/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.1407 - accuracy: 0.9397\n","Epoch 10/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1364 - accuracy: 0.9446\n","Epoch 11/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1323 - accuracy: 0.9455\n","Epoch 12/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1285 - accuracy: 0.9455\n","Epoch 13/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1248 - accuracy: 0.9484\n","Epoch 14/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.1212 - accuracy: 0.9494\n","Epoch 15/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1180 - accuracy: 0.9504\n","Epoch 16/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1148 - accuracy: 0.9514\n","Epoch 17/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1116 - accuracy: 0.9553\n","Epoch 18/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1086 - accuracy: 0.9582\n","Epoch 19/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.1056 - accuracy: 0.9601\n","Epoch 20/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.1027 - accuracy: 0.9601\n","Epoch 21/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0999 - accuracy: 0.9601\n","Epoch 22/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0970 - accuracy: 0.9601\n","Epoch 23/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0942 - accuracy: 0.9640\n","Epoch 24/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0914 - accuracy: 0.9660\n","Epoch 25/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0885 - accuracy: 0.9660\n","Epoch 26/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0857 - accuracy: 0.9679\n","Epoch 27/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0834 - accuracy: 0.9689\n","Epoch 28/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0801 - accuracy: 0.9689\n","Epoch 29/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.0773 - accuracy: 0.9689\n","Epoch 30/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0748 - accuracy: 0.9718\n","\n","------------------------\n","Evaluation of the Model\n","------------------------\n","9/9 [==============================] - 2s 220ms/step - loss: 0.1378 - accuracy: 0.9533\n","\n","Accuracy on the Testing dataset: 95.33073902130127 %\n","\n","--------------\n","ITERATION: 2\n","--------------\n","\n","---------------------------------------------------------------------------\n","There are 1028 images for the Training with their respectives 1028 labels.\n","There are 257 images for the Testing with their respectives 257 labels.\n","---------------------------------------------------------------------------\n","\n","\n","-----------------------------------------------------------------------------------------------------------\n","There are 496 negatives images and 532 positives images on the Training dataset: rate= 0.9323308270676691\n","There are 124 negatives images and 133 positives images on the Testing dataset: rate= 0.9323308270676691\n","-----------------------------------------------------------------------------------------------------------\n","\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 256)               6422784   \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 21,137,729\n","Trainable params: 6,423,041\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n","\n","------------------------------------\n","Training the Tranfer Learning Model\n","------------------------------------\n","\n","Epoch 1/30\n","33/33 [==============================] - 9s 246ms/step - loss: 0.3861 - accuracy: 0.8521\n","Epoch 2/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1844 - accuracy: 0.9222\n","Epoch 3/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.1680 - accuracy: 0.9300\n","Epoch 4/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1566 - accuracy: 0.9270\n","Epoch 5/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1464 - accuracy: 0.9300\n","Epoch 6/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1382 - accuracy: 0.9368\n","Epoch 7/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1314 - accuracy: 0.9426\n","Epoch 8/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.1255 - accuracy: 0.9475\n","Epoch 9/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.1154 - accuracy: 0.9533\n","Epoch 10/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1115 - accuracy: 0.9553\n","Epoch 11/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.1075 - accuracy: 0.9572\n","Epoch 12/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1038 - accuracy: 0.9601\n","Epoch 13/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0934 - accuracy: 0.9679\n","Epoch 14/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0887 - accuracy: 0.9728\n","Epoch 15/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0883 - accuracy: 0.9728\n","Epoch 16/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0819 - accuracy: 0.9728\n","Epoch 17/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0779 - accuracy: 0.9728\n","Epoch 18/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0756 - accuracy: 0.9747\n","Epoch 19/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0716 - accuracy: 0.9767\n","Epoch 20/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0675 - accuracy: 0.9786\n","Epoch 21/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0641 - accuracy: 0.9805\n","Epoch 22/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0617 - accuracy: 0.9805\n","Epoch 23/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.0582 - accuracy: 0.9815\n","Epoch 24/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0565 - accuracy: 0.9825\n","Epoch 25/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0539 - accuracy: 0.9835\n","Epoch 26/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0502 - accuracy: 0.9844\n","Epoch 27/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0467 - accuracy: 0.9864\n","Epoch 28/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0460 - accuracy: 0.9864\n","Epoch 29/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0431 - accuracy: 0.9883\n","Epoch 30/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0397 - accuracy: 0.9883\n","\n","------------------------\n","Evaluation of the Model\n","------------------------\n","9/9 [==============================] - 2s 221ms/step - loss: 0.1084 - accuracy: 0.9611\n","\n","Accuracy on the Testing dataset: 96.10894918441772 %\n","\n","--------------\n","ITERATION: 3\n","--------------\n","\n","---------------------------------------------------------------------------\n","There are 1028 images for the Training with their respectives 1028 labels.\n","There are 257 images for the Testing with their respectives 257 labels.\n","---------------------------------------------------------------------------\n","\n","\n","-----------------------------------------------------------------------------------------------------------\n","There are 496 negatives images and 532 positives images on the Training dataset: rate= 0.9323308270676691\n","There are 124 negatives images and 133 positives images on the Testing dataset: rate= 0.9323308270676691\n","-----------------------------------------------------------------------------------------------------------\n","\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n","_________________________________________________________________\n","flatten_7 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 256)               6422784   \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 21,137,729\n","Trainable params: 6,423,041\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n","\n","------------------------------------\n","Training the Tranfer Learning Model\n","------------------------------------\n","\n","Epoch 1/30\n","33/33 [==============================] - 9s 246ms/step - loss: 0.4070 - accuracy: 0.8298\n","Epoch 2/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1784 - accuracy: 0.9290\n","Epoch 3/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1593 - accuracy: 0.9348\n","Epoch 4/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1465 - accuracy: 0.9377\n","Epoch 5/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1356 - accuracy: 0.9465\n","Epoch 6/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1266 - accuracy: 0.9523\n","Epoch 7/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1175 - accuracy: 0.9533\n","Epoch 8/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1113 - accuracy: 0.9543\n","Epoch 9/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.1065 - accuracy: 0.9553\n","Epoch 10/30\n","33/33 [==============================] - 8s 244ms/step - loss: 0.1017 - accuracy: 0.9582\n","Epoch 11/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.0970 - accuracy: 0.9621\n","Epoch 12/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0919 - accuracy: 0.9669\n","Epoch 13/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0875 - accuracy: 0.9708\n","Epoch 14/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0810 - accuracy: 0.9737\n","Epoch 15/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.0759 - accuracy: 0.9757\n","Epoch 16/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0734 - accuracy: 0.9767\n","Epoch 17/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0680 - accuracy: 0.9776\n","Epoch 18/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0644 - accuracy: 0.9776\n","Epoch 19/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0615 - accuracy: 0.9796\n","Epoch 20/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0581 - accuracy: 0.9786\n","Epoch 21/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0547 - accuracy: 0.9815\n","Epoch 22/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0503 - accuracy: 0.9844\n","Epoch 23/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0476 - accuracy: 0.9864\n","Epoch 24/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0445 - accuracy: 0.9864\n","Epoch 25/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0422 - accuracy: 0.9874\n","Epoch 26/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0392 - accuracy: 0.9903\n","Epoch 27/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0366 - accuracy: 0.9903\n","Epoch 28/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0340 - accuracy: 0.9912\n","Epoch 29/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0313 - accuracy: 0.9912\n","Epoch 30/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0292 - accuracy: 0.9912\n","\n","------------------------\n","Evaluation of the Model\n","------------------------\n","9/9 [==============================] - 2s 223ms/step - loss: 0.1033 - accuracy: 0.9650\n","\n","Accuracy on the Testing dataset: 96.49805426597595 %\n","\n","--------------\n","ITERATION: 4\n","--------------\n","\n","---------------------------------------------------------------------------\n","There are 1028 images for the Training with their respectives 1028 labels.\n","There are 257 images for the Testing with their respectives 257 labels.\n","---------------------------------------------------------------------------\n","\n","\n","-----------------------------------------------------------------------------------------------------------\n","There are 496 negatives images and 532 positives images on the Training dataset: rate= 0.9323308270676691\n","There are 124 negatives images and 133 positives images on the Testing dataset: rate= 0.9323308270676691\n","-----------------------------------------------------------------------------------------------------------\n","\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 256)               6422784   \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 21,137,729\n","Trainable params: 6,423,041\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n","\n","------------------------------------\n","Training the Tranfer Learning Model\n","------------------------------------\n","\n","Epoch 1/30\n","33/33 [==============================] - 9s 247ms/step - loss: 0.6082 - accuracy: 0.7879\n","Epoch 2/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1889 - accuracy: 0.9212\n","Epoch 3/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1849 - accuracy: 0.9202\n","Epoch 4/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.1629 - accuracy: 0.9377\n","Epoch 5/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1457 - accuracy: 0.9455\n","Epoch 6/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1341 - accuracy: 0.9514\n","Epoch 7/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1247 - accuracy: 0.9553\n","Epoch 8/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.1156 - accuracy: 0.9582\n","Epoch 9/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1073 - accuracy: 0.9630\n","Epoch 10/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0998 - accuracy: 0.9650\n","Epoch 11/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0934 - accuracy: 0.9679\n","Epoch 12/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0872 - accuracy: 0.9689\n","Epoch 13/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0828 - accuracy: 0.9698\n","Epoch 14/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0777 - accuracy: 0.9728\n","Epoch 15/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0739 - accuracy: 0.9728\n","Epoch 16/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0709 - accuracy: 0.9737\n","Epoch 17/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.0678 - accuracy: 0.9757\n","Epoch 18/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0651 - accuracy: 0.9767\n","Epoch 19/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0623 - accuracy: 0.9767\n","Epoch 20/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0596 - accuracy: 0.9796\n","Epoch 21/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0562 - accuracy: 0.9815\n","Epoch 22/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0540 - accuracy: 0.9825\n","Epoch 23/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0519 - accuracy: 0.9835\n","Epoch 24/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0499 - accuracy: 0.9835\n","Epoch 25/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0475 - accuracy: 0.9844\n","Epoch 26/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0455 - accuracy: 0.9864\n","Epoch 27/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0431 - accuracy: 0.9864\n","Epoch 28/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0401 - accuracy: 0.9883\n","Epoch 29/30\n","33/33 [==============================] - 8s 244ms/step - loss: 0.0378 - accuracy: 0.9903\n","Epoch 30/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0353 - accuracy: 0.9922\n","\n","------------------------\n","Evaluation of the Model\n","------------------------\n","9/9 [==============================] - 2s 223ms/step - loss: 0.0567 - accuracy: 0.9844\n","\n","Accuracy on the Testing dataset: 98.44357967376709 %\n","\n","--------------\n","ITERATION: 5\n","--------------\n","\n","---------------------------------------------------------------------------\n","There are 1028 images for the Training with their respectives 1028 labels.\n","There are 257 images for the Testing with their respectives 257 labels.\n","---------------------------------------------------------------------------\n","\n","\n","-----------------------------------------------------------------------------------------------------------\n","There are 496 negatives images and 532 positives images on the Training dataset: rate= 0.9323308270676691\n","There are 124 negatives images and 133 positives images on the Testing dataset: rate= 0.9323308270676691\n","-----------------------------------------------------------------------------------------------------------\n","\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n","_________________________________________________________________\n","flatten_9 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 256)               6422784   \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 21,137,729\n","Trainable params: 6,423,041\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n","\n","------------------------------------\n","Training the Tranfer Learning Model\n","------------------------------------\n","\n","Epoch 1/30\n","33/33 [==============================] - 9s 248ms/step - loss: 0.3628 - accuracy: 0.8726\n","Epoch 2/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1933 - accuracy: 0.9202\n","Epoch 3/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1527 - accuracy: 0.9397\n","Epoch 4/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.1326 - accuracy: 0.9523\n","Epoch 5/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.1180 - accuracy: 0.9591\n","Epoch 6/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.1056 - accuracy: 0.9611\n","Epoch 7/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0961 - accuracy: 0.9640\n","Epoch 8/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0897 - accuracy: 0.9669\n","Epoch 9/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.0843 - accuracy: 0.9708\n","Epoch 10/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0762 - accuracy: 0.9737\n","Epoch 11/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0696 - accuracy: 0.9796\n","Epoch 12/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0641 - accuracy: 0.9825\n","Epoch 13/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0601 - accuracy: 0.9835\n","Epoch 14/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0555 - accuracy: 0.9854\n","Epoch 15/30\n","33/33 [==============================] - 8s 248ms/step - loss: 0.0514 - accuracy: 0.9854\n","Epoch 16/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0478 - accuracy: 0.9864\n","Epoch 17/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0445 - accuracy: 0.9893\n","Epoch 18/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0412 - accuracy: 0.9893\n","Epoch 19/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0399 - accuracy: 0.9903\n","Epoch 20/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0384 - accuracy: 0.9903\n","Epoch 21/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0361 - accuracy: 0.9912\n","Epoch 22/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0334 - accuracy: 0.9922\n","Epoch 23/30\n","33/33 [==============================] - 8s 245ms/step - loss: 0.0317 - accuracy: 0.9912\n","Epoch 24/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0307 - accuracy: 0.9912\n","Epoch 25/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0294 - accuracy: 0.9922\n","Epoch 26/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0290 - accuracy: 0.9922\n","Epoch 27/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0286 - accuracy: 0.9922\n","Epoch 28/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0280 - accuracy: 0.9922\n","Epoch 29/30\n","33/33 [==============================] - 8s 246ms/step - loss: 0.0272 - accuracy: 0.9922\n","Epoch 30/30\n","33/33 [==============================] - 8s 247ms/step - loss: 0.0279 - accuracy: 0.9922\n","\n","------------------------\n","Evaluation of the Model\n","------------------------\n","9/9 [==============================] - 2s 221ms/step - loss: 0.0879 - accuracy: 0.9689\n","\n","Accuracy on the Testing dataset: 96.88715934753418 %\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"5hF58IdCTW4h"},"source":["#Saving the calculated metrics in a .csv file"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"43_L7g0ptAsd","executionInfo":{"status":"ok","timestamp":1631685941457,"user_tz":300,"elapsed":407,"user":{"displayName":"MARIO ISAAC SALGUEDO BOHORQUEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvTo7MXgDxQwdUpjCHglQVpHuGZBo0Uu-K3u0G=s64","userId":"15580766531341648609"}},"outputId":"65b63cc1-30e2-476f-e936-3ab7b2205a33"},"source":["import pandas as pd\n","\n","path_csv = '/content/drive/MyDrive/Agglutination/'\n","name_metrics_csv = 'cv5_metrics.csv'\n","\n","dict_metrics_cv = dict({'Accuracy':accuracies, 'Precision':precisions, 'Sensitivity':sensitivities, 'Specificity':specificities, 'F1 Score':F1_scores, 'AUC': auc_values})\n","df_metrics_cv = pd.DataFrame(dict_metrics_cv)\n","df_metrics_cv.to_csv(path_csv + name_metrics_csv, index=False)\n","df_metrics_cv"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>F1 Score</th>\n","      <th>AUC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.953307</td>\n","      <td>0.941606</td>\n","      <td>0.969925</td>\n","      <td>0.935484</td>\n","      <td>0.955556</td>\n","      <td>0.990420</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.961089</td>\n","      <td>0.984252</td>\n","      <td>0.939850</td>\n","      <td>0.983871</td>\n","      <td>0.961538</td>\n","      <td>0.993088</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.964981</td>\n","      <td>1.000000</td>\n","      <td>0.932331</td>\n","      <td>1.000000</td>\n","      <td>0.964981</td>\n","      <td>0.994179</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.984436</td>\n","      <td>1.000000</td>\n","      <td>0.969925</td>\n","      <td>1.000000</td>\n","      <td>0.984733</td>\n","      <td>0.997393</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.968872</td>\n","      <td>0.992126</td>\n","      <td>0.947368</td>\n","      <td>0.991935</td>\n","      <td>0.969231</td>\n","      <td>0.996726</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Accuracy  Precision  Sensitivity  Specificity  F1 Score       AUC\n","0  0.953307   0.941606     0.969925     0.935484  0.955556  0.990420\n","1  0.961089   0.984252     0.939850     0.983871  0.961538  0.993088\n","2  0.964981   1.000000     0.932331     1.000000  0.964981  0.994179\n","3  0.984436   1.000000     0.969925     1.000000  0.984733  0.997393\n","4  0.968872   0.992126     0.947368     0.991935  0.969231  0.996726"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"C2d0TUnBTw8Q"},"source":["#Statistics of calculated metrics"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"gjAGE_h_tAvW","executionInfo":{"status":"ok","timestamp":1631685961658,"user_tz":300,"elapsed":416,"user":{"displayName":"MARIO ISAAC SALGUEDO BOHORQUEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvTo7MXgDxQwdUpjCHglQVpHuGZBo0Uu-K3u0G=s64","userId":"15580766531341648609"}},"outputId":"d1bd9f27-f203-4886-c85f-720f54ea6f6a"},"source":["df_metrics_cv.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Sensitivity</th>\n","      <th>Specificity</th>\n","      <th>F1 Score</th>\n","      <th>AUC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.966537</td>\n","      <td>0.983597</td>\n","      <td>0.951880</td>\n","      <td>0.982258</td>\n","      <td>0.967208</td>\n","      <td>0.994361</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.011543</td>\n","      <td>0.024365</td>\n","      <td>0.017310</td>\n","      <td>0.026989</td>\n","      <td>0.011001</td>\n","      <td>0.002827</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.953307</td>\n","      <td>0.941606</td>\n","      <td>0.932331</td>\n","      <td>0.935484</td>\n","      <td>0.955556</td>\n","      <td>0.990420</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.961089</td>\n","      <td>0.984252</td>\n","      <td>0.939850</td>\n","      <td>0.983871</td>\n","      <td>0.961538</td>\n","      <td>0.993088</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.964981</td>\n","      <td>0.992126</td>\n","      <td>0.947368</td>\n","      <td>0.991935</td>\n","      <td>0.964981</td>\n","      <td>0.994179</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.968872</td>\n","      <td>1.000000</td>\n","      <td>0.969925</td>\n","      <td>1.000000</td>\n","      <td>0.969231</td>\n","      <td>0.996726</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.984436</td>\n","      <td>1.000000</td>\n","      <td>0.969925</td>\n","      <td>1.000000</td>\n","      <td>0.984733</td>\n","      <td>0.997393</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Accuracy  Precision  Sensitivity  Specificity  F1 Score       AUC\n","count  5.000000   5.000000     5.000000     5.000000  5.000000  5.000000\n","mean   0.966537   0.983597     0.951880     0.982258  0.967208  0.994361\n","std    0.011543   0.024365     0.017310     0.026989  0.011001  0.002827\n","min    0.953307   0.941606     0.932331     0.935484  0.955556  0.990420\n","25%    0.961089   0.984252     0.939850     0.983871  0.961538  0.993088\n","50%    0.964981   0.992126     0.947368     0.991935  0.964981  0.994179\n","75%    0.968872   1.000000     0.969925     1.000000  0.969231  0.996726\n","max    0.984436   1.000000     0.969925     1.000000  0.984733  0.997393"]},"metadata":{},"execution_count":9}]}]}